---
title: Metrics and adequacy criteria
category: definition
author: Andrey Sadovykh
layout: page
---

# Intro

(D. Hubbard, How to Measure Anything, 2010) Everything is measurable

If X is something we care about, then X, by definition, must be detectable.
  How could we care about things like “quality,” “risk,” “security,” or “public image” if these things were totally undetectable, directly or indirectly?
  If we have reason to care about some unknown quantity, it is because we think it corresponds to desirable or undesirable results in some way.
If X is detectable, then it must be detectable in some amount. 
  If you can observe a thing at all, you can observe more of it or less of it
  If we can observe it in some amount, then it must be measurable.


Example for discussion for quality measurement. Garvin's tansendental view. Discuss example of compering Manet and Picaso artwork. Which one is better (more quality)?

# How does this looks for Software Quality

Example below for ISO 9126

![Attributes-metrics mapping example](http://www.plantuml.com/plantuml/png/ZLN1Rbj73BpxAtXC3HH5UoZGdk8OCM2WRbpR-W1gTvv5T9VxIdBjA5zVwQqTHBKRwoRjScP9pc3UUm-sgAAvydnoIfUtdtww_7XEl_tyow_qL-SYiQMp29Dr3_Z9wIbTT4qXJPUxtS4ftNO9Nilulp-uGfYat-aQbg31zw0saU6VBeOA3QUAMB1dANNZz5rWQcP8GQt7tCCNtAK6hCsmLn_-izSrR63hp27h0lAj1-g0d--EYx0c70BFyWO6JQ1evC6QsRBJk_bhGp-CaP6wVUTPVxgdjO7JPcpk1aMUsrrW7A-GN86LGYfeZNW4b2QMqWsxDgxkFboC1Ywubw2xLc0lfxX1QW-mxQ2PhDLdZWNxT7s4PDvJWllK2za0oHXbvTyEij8C6zjwZVDEAfxLpnID-jTwcbwuwG-mwH4yKpFg3gCm5XMzNz2VthJ40C6icGyBHXYda0Set0zHgtsjSuXFlFH9nh5xQrd2nscI9D3Xtj7U1spuGPhzLn2Vcpg68E-gb2AEr3Jxa7DNqBebq2gao1VUFtL8SNwzelt2AcgpBNNdUmmhyypffOluizHUwR7PtwLnfiqEN91F5j-91ej-A-6PSjb-EKu-oT2GQKlYtk6ZYnt_FOx4rxaiCK1fGGs6stX3jum9APn4mrhk2Pbu2jW1ontyc2nABOCMGoFJUai1ZqNJwsPni9VCSnmt5kzBzpyKZmHz46kwd_8fhpoub2DzBQDws63arO_uB1xGXF-FEfsAf71wbDXGYmti8FHkC1TEHufaetW9qARGy9FtqFpqgVWN)




#  Learning goals

Define measurement and metrics, specifically in the context of software quality.
Enumerate several ways measurement can go wrong (so you can avoid them!).
Evaluate measurement data in terms of scale, precision, reliability, validity, etc.
Describe mechanisms to develop a (valid!) metric or measurement for your quality concerns. 
Evaluate new metrics with a critical eye.
Enumerate approaches to setting up a successful metrics program in your organization (bearing in mind potential risks). 

# Definitions
Software quality metric. IEEE 1061 says:
“A software quality metric is a function whose inputs are software data and whose output is a single numerical value that can be interpreted as the degree to which software possesses a given attribute that affects its quality.” 

Measurement 

Def by (D. Hubbard, How to Measure Anything, 2010)

Measurement: a quantitatively expressed reduction of uncertainty based on one or more observations.
Definition:
Measurement of some attribute of a set of things is the process of assigning numbers or other symbols to the things in such a way that relationships of the numbers or symbols reflect relationships of the attributes of the things being measured. (W. Sarle, 1997)

Measurement basics
What does the measurement represent?
How accurate is the measurement?
How precise is the measurement?
What is the resolution of the measurement?

# What can go wrong with metrics

![Dilbert gets rich](http://dilbert.com/strips/comic/1995-11-13/
)

In summary:
Bad statistics: A basic misunderstanding of measurement theory and what is being measured.
Bad decisions: The incorrect use of measurement data, leading to unintended side effects.
Bad incentives: Disregard for the human factors, or how the cultural change of taking measurements will affect people

The Dangers of Using Software Metrics to (Mis)Manage 
There sometimes is a decidedly dark side to software metrics that many of us have observed, but few have openly discussed. It is clear to me that we often get what we ask for with software metrics and we sometimes get side effects from the metrics that overshadow any value we might derive from the metrics information. Whether or not our models are correct, and regardless of how well or poorly we collect and compute software metrics, people’s behaviors change in predictable ways to provide the answers management asks for when metrics are applied. I believe most people in this field are hard working and well intentioned, and even though some of the behaviors caused by metrics may seem strange, odd, or even silly, they are serious responses created in organizations because of the use of metrics. Some of these actions seriously hamper productivity and can effectively reduce quality (“The Darker Side of Metrics,” Eighteenth Ann. Pacific Northwest Software Quality Conf., Pacific Northwest Software Quality Conf., Portland, Ore., 2000, pp. 265-272; http://www.pnsqc. org/hot/proceedings.htm). 

## Metrics biases and falacies

Examples:
Streetlight effect
McNamara Fallacy
Wrong correlations
Confounding variables, 
wrong representation.

# Are your measurements right ?

## Representation condition
A numerical model should make sense in terms of the real-world entity it describes.
More formally: a measurement should map real world entities into numbers and real-world relations into numerical relations such that the real-world relations are preserved in the numerical relations. 
Example: LOC satisfies the representation condition for physical program size, but not functional program size.

Resolution, accuracy, precision of your measurements

## Scale
Scale: the type of data being measured.
The scale dictates what sorts of analysis/arithmetic is legitimate or meaningful.
Your options are:
Nominal: categories
Ordinal: order, but no magnitude.
Interval: order, magnitude, but no zero.
Ratio: Order, magnitude, and zero.
Absolute: special case of ratio.

For example, software testers often use a ratio to represent the number of defects found to the number of defects fixed during testing. A ratio greater than one during a specified time period, indicates that developers are discovering problems faster than they can fix them. When the ratio is below one, developers are reducing the number of known problems. An example of a nominal value would be a case where developers assign priority or severity levels to defects, entering this information into a defect-tracking database for software testing.
Ordinal values can represent a position, such as when an athlete finishes a race first, second, or third. You must preserve the ratio relationship—by not mixing ratio values with ordinal values, for example—to make measurement meaningful.

## Understanding data

### Mean, median and mode

What is the difference between “average” and “mean”? An average is a single value that is meant to be representative of a set of values, as such the mean, the median and the mode are all averages, but be careful because this is not the common usage where average tends to be equated with arithmetic mean.

Geometric mean: which indicates the central tendency or typical value of a set of numbers by using the product of their values (as opposed to the arithmetic mean which uses their sum). The geometric mean is defined as the nth root (where n is the count of numbers) of the product of the numbers. A geometric mean is often used when comparing different items – finding a single "figure of merit" for these items – when each item has multiple properties that have different numeric ranges.[1] For example, the geometric mean can give a meaningful "average" to compare two companies which are each rated at 0 to 5 for their environmental sustainability, and are rated at 0 to 100 for their financial viability. If an arithmetic mean was used instead of a geometric mean, the financial viability is given more weight because its numeric range is larger- so a small percentage change in the financial rating (e.g. going from 80 to 90) makes a much larger difference in the arithmetic mean than a large percentage change in environmental sustainability (e.g. going from 2 to 5). The use of a geometric mean "normalizes" the ranges being averaged, so that no range dominates the weighting, and a given percentage change in any of the properties has the same effect on the geometric mean. So, a 20% change in environmental sustainability from 4 to 4.8 has the same effect on the geometric mean as a 20% change in financial viability from 60 to 72.

In mathematics, the harmonic mean (sometimes called the subcontrary mean) is one of several kinds of average. Typically, it is appropriate for situations when the average of rates is desired.

The harmonic mean is one of the three Pythagorean means. For all positive data sets containing at least one pair of nonequal values, the harmonic mean is always the least of the three means, while the arithmetic mean is always the greatest of the three and the geometric mean is always in between. (If all values in a nonempty dataset are equal, the three means are always equal to one another; e.g. the harmonic, geometric, and arithmetic means of {2, 2, 2} are all 2.)


### Range, standard deviation, skewness, kurtosis

Standard deviation shows how much variation or dispersion exists in a dataset. For a finite set of numbers, the standard deviation is found by taking the square root of the average of the squared differences of the values from their average value. 

Skewness measures the degree of asymmetry of a distribution. A value of 0 means a symmetric distribution, while a positive value means the distribution is skewed to the right. The largest the skewness the longer the tail of the distribution.

Kurtosis is a measurement of the flatness of an approximately symmetric distribution. The “reference” of kurtosis is given by the normal distribution for which its value is 3. A distribution which kurtosis higher than 3 is less peaked than the Normal distribution.  A distribution with kurtosis lower than 3 is more peaked than a Normal distribution.  The kurtosis of a uniform distribution is 4.2. Some authors use what is called the Fisher kurtosis which is identical to the other except that the value of 3 is subtracted to have 0 as a reference for a Normal distribution.


### Correlations

Correlation is a general term that describes whether two variables are associated. The term associated means ‘go together’, that is, knowing the value of one variable, X, enables better prediction of a correlated (associated) variable, Y.
Correlation does not imply causality. Height and vocabulary of children are correlated – both increase with age. Clearly, an increase in height does not cause an increase in vocabulary, or vice versa.
To see whether two variables are associated or not the best instrument is the scatter plot. 

A scatter plots reveals relationships or association between two variables. Such relationships manifest themselves by any non-random structure in the plot. Scatter plots help answer the following questions: 
Are variables X and Y related? 
Are variables X and Y linearly related? 
Are variables X and Y non-linearly related? 
Does the variation in Y change depending on X? 
Are there outliers?
Are there influential points?

#### Problems with correlations

Confounding variables

Other causes of spurious correlation:
Both variables change with time
Response and explanatory variable are swapped in our model. 
To substantiate causation:
Provide a theory (from domain knowledge, independent of data)
Show correlation
Demonstrate ability to predict new cases (replicate/validate)


### Significance

Statistical significance: the probability that an observed effect is not due to random chance.
Blindly computing statistics without considering the significance of the results is dangerous.
Short of sophisticated statistics, increase confidence in your claims by sanity checking your data.


# How to develop metric or measurement

Measurements validity

Construct – Are we measuring what we intended to measure?
Predictive – The extent to which the measurement can be used to explain some other characteristic of the entity being measured
External validity – Concerns the generalization of the findings to contexts and environments, other than the one studied



