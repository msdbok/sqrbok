---
title: Overview. 2.2 Analysis. Properties
category: verification
author: Andrey Sadovykh
layout: page
---

---

## 🔐 Software Properties Verified by Static Analysis

**Definition:**  
Safety properties ensure that _nothing bad happens_ during program execution. These properties guarantee the system does **not reach an undesirable state**.

**Examples:**

- No **deadlocks** (e.g. multiple processes waiting forever for each other).
    
- No attempt to **access an empty buffer** (e.g. removing an item that isn’t there).
    

**Purpose:**  
Used to ensure the **consistency of program state**.

**How?**

- Enforce **mutual exclusion**: Shared resources must be accessed atomically (only one thread/process at a time).
    
- Use **condition synchronization**: Certain actions are delayed until the system is in a safe state.
    

---

### ✅ Liveness Properties

**Definition:**  
Liveness properties ensure that _something good eventually happens_. They are used to guarantee **progress** in the system.

**Prevents:**

- **Starvation**: A process never gets needed resources (like CPU time).
    
- **Dormancy**: A waiting process is never resumed.
    
- **Premature termination**: A process ends before it should.
    

---

### ⚖️ Fairness Properties

**Definition:**  
A subset of liveness properties. **Fairness** means that every process or action gets its fair share _infinitely often_.

**Example:**

- A process is guaranteed to be activated repeatedly (e.g. each thread gets a turn in a scheduler).
    

---

### ⏳ Temporal Properties

**Definition:**  
Temporal properties describe how states are related **over time**. Unlike **state properties** (which describe a single point), **temporal properties** describe **paths or sequences of states**.

**Example:**  
“If a message is sent in one state, it will eventually be received in a future state.”

**Notation (common temporal logic):**

- **α**: α holds in the current state
    
- **Xα**: α holds in the _next_ state
    
- **Fγ**: γ holds _eventually_ (in the future)
    
- **Gλ**: λ holds _always_ from now on
    
- **α U β**: α holds _until_ β becomes true
    

---

## 🧰 Analysis Fault Taxonomy (Common Issues Detected by Static Analysis)

### 🧵 Concurrency Errors

- **Race conditions**: Multiple threads access shared data unsafely.
    
- **Deadlock**: Processes wait on each other in a cycle.
    
- **Improper lock usage**
    

### ⚠️ Exceptional Conditions

- Integer overflow/underflow
    
- Division by zero
    
- Unhandled exceptions
    
- Incorrect type conversions
    

### 🛡️ Input Validation Issues

- **Command injection**
    
- **Cross-site scripting (XSS)**
    
- **Format string vulnerabilities**
    
- Use of **tainted data** (untrusted user input)
    

### 🧹 Code Quality Issues

- Poor **code metrics**
    
- **Unused variables**
    

### 💾 Memory Errors

- **Buffer overruns**
    
- **Null or invalid pointer dereference**
    
- **Double free** or freeing unallocated memory
    
- **Memory leaks**
    
- Use of **uninitialized variables**
    

### 🔄 Resource/Protocol Misuse

- Incorrect function call order
    
- Forgetting to initialize or free resources
    

### 🧠 Design & Structural Issues

- Complex **dependencies**
    
- Complicated **heap structures**
    
- Incomplete or messy **call graphs**
    

### 🔐 Security Weaknesses

- **Privilege escalation**
    
- **Denial of service (DoS)**
    
- Execution of **dynamic code**
    
- **Insecure randomness**
    
- Violating **least privilege principle**
    

---

## 🧪 How does the Analysis work?

**Software analysis** involves creating a **model** of the system (either manually or automatically), and then **verifying properties** of the system using the model—**without running** the actual software.

> By abstracting away unnecessary details, we can prove or disprove whether certain properties hold.

---

## 🎯 Precision of Static Analysis

- **Soundness**:  
    If the tool says the program is **correct**, it truly is.  
    ✅ No false negatives (i.e. no missed bugs).
    
- **Completeness**:  
    If the tool reports an **issue**, it’s real.  
    ✅ No false positives (i.e. no bogus warnings).
    

> ❗ In practice, **no static analysis can be both sound and complete** and still **terminate** on all programs.

### Reality of Static Analysis:

- **Perfect static analysis is undecidable**: it’s impossible to create one that works perfectly for all programs.
    
- All analyses **use abstraction** to approximate behavior.
    
- Still, static analysis tools are extremely **useful in practice**.
    

---

# Soundness and Completeness in Static Analysis

## What is Soundness?

- A **sound** static analysis _over-approximates_ the behaviors of a program.
    
- This means it **guarantees to find all violations** of a given property — if a bug exists, the tool will catch it.
    
- However, because it is conservative, it may report **false alarms** — warnings about issues that **cannot actually happen** in the real program.
    

**In short:**  
Sound analysis → _No real bugs missed_ but may have _false positives_.

---

## What is Completeness?

- A **complete** static analysis _under-approximates_ the program's behavior.
    
- This means that **every violation it reports is real** — no false alarms.
    
- But it **might miss some real bugs** because it only reports violations it can confidently confirm.
    

**In short:**  
Complete analysis → _All reported bugs are real_ but may _miss some bugs_.

---

## Why Can't We Have Both Soundness and Completeness?

- According to **Rice’s Theorem**, there are fundamental limits on what automated program analysis can achieve.
    
- It is impossible for a static analysis to be **sound, complete, and always terminate** on all programs with arbitrary complexity (such as unbounded memory structures).
    

In other words, no tool can:

- Miss no errors (sound)
    
- Have no false alarms (complete)
    
- Automatically analyze every program and always finish (terminating)
    

---

## Practical Implications

- **For high assurance (critical systems), soundness is vital:**  
    If a tool says _no errors_, then there really are none. This means we accept some false alarms.
    
- **For general software development, bug finding is the main goal:**  
    Most tools prioritize reducing the number of bugs over guaranteeing to find all bugs.  
    Users often cannot tolerate many false alarms, so tools sacrifice soundness to be more practical.
    
- Some tools trade **automation for accuracy** by requiring **user annotations** or guidance.
    

---

## Examples of Commercial Tools

- Tools like **Coverity**, **CodeSonar**, **Fortify**, **KlocWork**, and **LDRA** are **neither sound nor complete**.
    
- Despite this, they are **effective in practice** at finding real bugs.
    
- They each use different methods and balance between false alarms and missed bugs differently.
    

---

## What About Simpler Tools Like Lint and FindBugs?

- These tools use **pattern matching** rather than deep semantic analysis.
    
- They are **neither sound nor complete**, but they are still useful and widely used.
    
- They help catch common bugs quickly and easily.
    

---

### Summary Table

|Property|What it Means|Pros|Cons|
|---|---|---|---|
|**Sound**|No bugs missed (no false negatives)|High assurance|May report false alarms (false positives)|
|**Complete**|No false alarms (no false positives)|Accurate warnings|May miss real bugs|
|**Neither**|Mix of both|Practical and efficient|Some bugs missed, some false alarms|

